{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5991f5-958d-43a8-bae5-971608597cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Feature engineering optimizado y \"future‑proof\" para el proyecto Prometeo.\n",
    "Genera ../data/processed/Pipeline_test1.csv\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import logging\n",
    "import gc      # Para gestión de memoria\n",
    "from functools import partial\n",
    "import warnings\n",
    "\n",
    "# Suprimir advertencias que no son críticas\n",
    "warnings.filterwarnings('ignore', category=pd.errors.PerformanceWarning)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Configuración de registro\n",
    "# ------------------------------------------------------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Parámetros globales\n",
    "# ------------------------------------------------------------------\n",
    "DATA_RAW   = Path(\"../data/raw\")\n",
    "DATA_PROD  = Path(\"../data/processed\")\n",
    "DATA_PROD.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "REFERENCE_DATE = pd.Timestamp(\"2024-01-01\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Carga de datos - con tipos optimizados\n",
    "# ------------------------------------------------------------------\n",
    "def read_with_dtypes(filepath, date_cols=None, cat_cols=None):\n",
    "    \"\"\"Lee CSV con tipos de datos optimizados.\"\"\"\n",
    "    dtypes = {}\n",
    "    parse_dates = date_cols if date_cols else []\n",
    "    \n",
    "    if cat_cols:\n",
    "        for col in cat_cols:\n",
    "            dtypes[col] = 'category'\n",
    "            \n",
    "    return pd.read_csv(filepath, dtype=dtypes, parse_dates=parse_dates)\n",
    "\n",
    "# Definir tipos para cada dataset\n",
    "transactions = read_with_dtypes(\n",
    "    DATA_RAW / \"transactions.csv\",\n",
    "    date_cols=[\"date\"],\n",
    "    cat_cols=[\"merchant_category\"]\n",
    ")\n",
    "\n",
    "demographics = read_with_dtypes(\n",
    "    DATA_RAW / \"demographics.csv\", \n",
    "    cat_cols=[\"income_range\", \"risk_profile\", \"occupation\"]\n",
    ")\n",
    "\n",
    "products = read_with_dtypes(\n",
    "    DATA_RAW / \"products.csv\",\n",
    "    date_cols=[\"contract_date\"],\n",
    "    cat_cols=[\"product_type\"]\n",
    ")\n",
    "\n",
    "logging.info(\"Archivos cargados con tipos optimizados\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. DEMOGRAPHICS – age_range_sturges\n",
    "# ------------------------------------------------------------------\n",
    "# Vectorizado sin usar apply\n",
    "breaks = np.linspace(18, 70, 9)\n",
    "labels = [\"18–24\", \"25–31\", \"32–38\", \"39–45\",\n",
    "          \"46–52\", \"53–59\", \"60–66\", \"67–70\"]\n",
    "\n",
    "demographics[\"age_range_sturges\"] = pd.cut(\n",
    "    demographics[\"age\"],\n",
    "    bins=breaks,\n",
    "    labels=labels,\n",
    "    right=True,\n",
    "    include_lowest=True\n",
    ")\n",
    "demographics[\"age_range_sturges\"] = demographics[\"age_range_sturges\"].astype('category')\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. PRODUCTS – flags, fechas y métricas\n",
    "# ------------------------------------------------------------------\n",
    "# Más eficiente que crear una copia completa\n",
    "products[\"product_type\"] = products[\"product_type\"].replace(\"investment_account\", \"investment\")\n",
    "\n",
    "# Crea flags de producto de manera vectorizada\n",
    "flag_cols = [\"checking_account\", \"savings_account\", \"credit_card\", \n",
    "             \"insurance\", \"investment\"]\n",
    "\n",
    "# Preprocesamiento más eficiente de productos\n",
    "prod_pivoted = products.pivot_table(\n",
    "    index=\"user_id\", \n",
    "    columns=\"product_type\", \n",
    "    values=\"contract_date\", \n",
    "    aggfunc=\"count\",\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Convertir a indicadores binarios de manera más eficiente\n",
    "for col in flag_cols:\n",
    "    if col in prod_pivoted.columns:\n",
    "        prod_pivoted[col] = (prod_pivoted[col] > 0).astype(bool)\n",
    "    else:\n",
    "        prod_pivoted[col] = False\n",
    "\n",
    "prod_pivoted.reset_index(inplace=True)\n",
    "\n",
    "# Obtener primer y segundo producto de forma más eficiente\n",
    "prod_sorted = products.sort_values([\"user_id\", \"contract_date\"])\n",
    "first_products = prod_sorted.groupby(\"user_id\").first().reset_index()\n",
    "first_products.rename(columns={\n",
    "    \"product_type\": \"primer_producto\", \n",
    "    \"contract_date\": \"fecha_primer_producto\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Obtener el segundo producto de forma más eficiente\n",
    "prod_with_rank = prod_sorted.assign(\n",
    "    rank=prod_sorted.groupby(\"user_id\").cumcount() + 1\n",
    ")\n",
    "second_products = prod_with_rank[prod_with_rank[\"rank\"] == 2].drop(columns=[\"rank\"])\n",
    "second_products.rename(columns={\n",
    "    \"product_type\": \"segundo_producto\", \n",
    "    \"contract_date\": \"fecha_segundo_producto\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Combinar todo\n",
    "prod_agg = first_products[[\"user_id\", \"primer_producto\", \"fecha_primer_producto\"]].merge(\n",
    "    second_products[[\"user_id\", \"segundo_producto\", \"fecha_segundo_producto\"]], \n",
    "    on=\"user_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Combinar con los flags\n",
    "prod_agg = prod_agg.merge(prod_pivoted, on=\"user_id\", how=\"left\")\n",
    "\n",
    "# Procesar fechas y calcular métricas\n",
    "prod_agg[\"fecha_segundo_producto\"] = prod_agg[\"fecha_segundo_producto\"].fillna(\n",
    "    pd.Timestamp(\"1900-01-01\")\n",
    ")\n",
    "\n",
    "# Vectorizado sin apply\n",
    "prod_agg[\"dias_entre_productos\"] = (\n",
    "    (prod_agg[\"fecha_segundo_producto\"] - prod_agg[\"fecha_primer_producto\"])\n",
    "    .dt.days.fillna(0).astype('int32')\n",
    ")\n",
    "prod_agg[\"antiguedad_cliente\"] = (\n",
    "    (REFERENCE_DATE - prod_agg[\"fecha_primer_producto\"]).dt.days.astype('int32')\n",
    ")\n",
    "prod_agg[\"numero_productos\"] = prod_agg[flag_cols].sum(axis=1).astype('int8')\n",
    "\n",
    "# Combinación de productos\n",
    "\n",
    "def _combo(row):\n",
    "    activos = [c for c in flag_cols if row[c]]\n",
    "    \n",
    "    # Sin productos\n",
    "    if not activos:\n",
    "        return \"sin_productos\"\n",
    "    \n",
    "    # Un solo producto\n",
    "    if len(activos) == 1:\n",
    "        return activos[0]\n",
    "    \n",
    "    # Para dos productos, ordenamos para consistencia\n",
    "    if len(activos) == 2:\n",
    "        return \" + \".join(sorted(activos))\n",
    "    \n",
    "    # Si hay más de 2 productos (caso no esperado), usar \"multi_producto\"\n",
    "    return \"multi_producto\"\n",
    "\n",
    "# Usar procesamiento normal para esta operación\n",
    "prod_agg[\"combinacion_productos\"] = prod_agg.apply(_combo, axis=1)\n",
    "\n",
    "# Mapeo completo para todas las combinaciones de dos productos\n",
    "mapeo_completo = {\n",
    "    # Combinaciones con checking_account\n",
    "    \"checking_account + credit_card\": \"checking_account + credit_card\",\n",
    "    \"checking_account + insurance\": \"checking_account + insurance\",\n",
    "    \"checking_account + investment\": \"checking_account + investment\",\n",
    "    \"checking_account + savings_account\": \"checking_account + savings_account\",\n",
    "    \n",
    "    # Combinaciones con credit_card\n",
    "    \"credit_card + insurance\": \"credit_card + insurance\",\n",
    "    \"credit_card + investment\": \"credit_card + investment\",\n",
    "    \"credit_card + savings_account\": \"credit_card + savings_account\",\n",
    "    \n",
    "    # Combinaciones con insurance\n",
    "    \"insurance + investment\": \"insurance + investment\",\n",
    "    \"insurance + savings_account\": \"insurance + savings_account\",\n",
    "    \n",
    "    # Combinación de investment y savings_account\n",
    "    \"investment + savings_account\": \"investment + savings_account\"\n",
    "}\n",
    "\n",
    "# Aplicar mapeo a las combinaciones de dos productos\n",
    "def aplicar_mapeo_completo(x):\n",
    "    # Si es una combinación de dos productos, aplicar el mapeo\n",
    "    if \"+\" in x:\n",
    "        return mapeo_completo.get(x, x)\n",
    "    # Caso contrario, mantener el valor original\n",
    "    return x\n",
    "\n",
    "prod_agg[\"combinacion_productos\"] = prod_agg[\"combinacion_productos\"].map(aplicar_mapeo_completo)\n",
    "prod_agg[\"combinacion_productos\"] = prod_agg[\"combinacion_productos\"].astype('category')\n",
    "\n",
    "del prod_sorted, first_products, second_products, prod_pivoted, prod_with_rank\n",
    "gc.collect()  # Liberar memoria\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. TRANSACTIONS – estadísticas por usuario\n",
    "# ------------------------------------------------------------------\n",
    "# Conteos por categoría usando pivot_table (más eficiente)\n",
    "cat_counts = transactions.pivot_table(\n",
    "    index=\"user_id\",\n",
    "    columns=\"merchant_category\",\n",
    "    values=\"transaction_id\",\n",
    "    aggfunc=\"count\",\n",
    "    fill_value=0\n",
    ").add_suffix(\"_count\").reset_index()\n",
    "\n",
    "# Calcular estadísticas básicas (vectorizado)\n",
    "tx_basic = (\n",
    "    transactions.groupby(\"user_id\")\n",
    "      .agg(\n",
    "          total_transacciones        = (\"transaction_id\", \"count\"),\n",
    "          monto_promedio_transaccion = (\"amount\", \"mean\"),\n",
    "          total_spend                = (\"amount\", \"sum\"),\n",
    "          n_meses_activos            = (\"date\", lambda s: s.dt.to_period(\"M\").nunique()),\n",
    "          recencia_transaccion       = (\"date\", lambda s: (REFERENCE_DATE - s.max()).days)\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Obtener categoría favorita de forma más eficiente\n",
    "cnt_cols = [c for c in cat_counts.columns if c.endswith(\"_count\")]\n",
    "# Usar argmax() en lugar de idxmax() para mayor velocidad\n",
    "cat_counts[\"categoria_favorita\"] = cat_counts[cnt_cols].values.argmax(axis=1)\n",
    "# Mapear índices a nombres de categorías\n",
    "cat_names = [c.replace(\"_count\", \"\") for c in cnt_cols]\n",
    "cat_counts[\"categoria_favorita\"] = cat_counts[\"categoria_favorita\"].apply(\n",
    "    lambda idx: cat_names[idx]\n",
    ")\n",
    "\n",
    "# Análisis de gastos por categoría vectorizado\n",
    "sp_by_cat = transactions.pivot_table(\n",
    "    index=\"user_id\", \n",
    "    columns=\"merchant_category\", \n",
    "    values=\"amount\", \n",
    "    aggfunc=\"sum\",\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Estas operaciones son más rápidas que usar idxmax con series\n",
    "fav_idx = sp_by_cat.values.argmax(axis=1)\n",
    "sp_fav = np.take_along_axis(sp_by_cat.values, fav_idx[:, np.newaxis], axis=1).squeeze()\n",
    "\n",
    "# Crear DataFrame con los resultados\n",
    "tx_money = pd.DataFrame({\n",
    "    \"user_id\": sp_by_cat.index,\n",
    "    \"categoria_favorita_monto\": [sp_by_cat.columns[i] for i in fav_idx],\n",
    "    \"total_spend_fav\": sp_fav\n",
    "})\n",
    "\n",
    "# Calcular HHI de forma vectorizada\n",
    "row_sums = sp_by_cat.sum(axis=1)\n",
    "hhi = ((sp_by_cat.div(row_sums, axis=0))**2).sum(axis=1)\n",
    "tx_money[\"hhi\"] = hhi.values\n",
    "\n",
    "# Análisis temporal por mes\n",
    "tx_month = transactions.copy()\n",
    "tx_month[\"mes\"] = tx_month[\"date\"].dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "# Agrupación por mes (vectorizado)\n",
    "month_agg = tx_month.groupby([\"user_id\", \"mes\"]).agg(\n",
    "    monto_mes=(\"amount\", \"sum\"),\n",
    "    transacciones_mes=(\"transaction_id\", \"count\")\n",
    ").reset_index()\n",
    "\n",
    "# Encontrar meses con más transacciones y mayor monto\n",
    "user_max_tx = month_agg.loc[month_agg.groupby(\"user_id\")[\"transacciones_mes\"].idxmax()]\n",
    "m_best = user_max_tx[[\"user_id\", \"mes\"]].rename(columns={\"mes\": \"mes_mas_compras\"})\n",
    "\n",
    "user_max_amt = month_agg.loc[month_agg.groupby(\"user_id\")[\"monto_mes\"].idxmax()]\n",
    "m_best_amt = user_max_amt[[\"user_id\", \"mes\"]].rename(columns={\"mes\": \"mes_mayor_monto\"})\n",
    "\n",
    "# Calcular diferencias entre meses\n",
    "month_agg = month_agg.sort_values([\"user_id\", \"mes\"])\n",
    "month_diffs = month_agg.groupby(\"user_id\")[\"monto_mes\"].diff().fillna(0)\n",
    "month_pcts = month_agg.groupby(\"user_id\")[\"monto_mes\"].pct_change().fillna(0)\n",
    "\n",
    "diffs = pd.DataFrame({\n",
    "    \"user_id\": month_agg[\"user_id\"].unique(),\n",
    "    \"variacion_mensual_promedio\": month_diffs.groupby(month_agg[\"user_id\"]).mean().values,\n",
    "    \"variacion_mensual_promedio_pct\": month_pcts.groupby(month_agg[\"user_id\"]).mean().values\n",
    "})\n",
    "\n",
    "# Combinar todos los resultados\n",
    "tx_full = (tx_basic\n",
    "    .merge(cat_counts, on=\"user_id\", how=\"left\")\n",
    "    .merge(tx_money,   on=\"user_id\", how=\"left\")\n",
    "    .merge(m_best,     on=\"user_id\", how=\"left\")\n",
    "    .merge(m_best_amt, on=\"user_id\", how=\"left\")\n",
    "    .merge(diffs,      on=\"user_id\", how=\"left\")\n",
    ")\n",
    "\n",
    "tx_full[\"share_fav\"] = tx_full[\"total_spend_fav\"] / tx_full[\"total_spend\"]\n",
    "tx_full[\"categoria_favorita_monto\"] = tx_full[\"categoria_favorita_monto\"].astype('category')\n",
    "\n",
    "del tx_month, month_agg, user_max_tx, user_max_amt, month_diffs, month_pcts\n",
    "gc.collect()  # Liberar memoria\n",
    "\n",
    "logging.info(\"Transacciones agregadas de forma optimizada\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. DATASET FINAL y transformaciones\n",
    "# ------------------------------------------------------------------\n",
    "df = (demographics\n",
    "      .merge(prod_agg, on=\"user_id\", how=\"left\")\n",
    "      .merge(tx_full,  on=\"user_id\", how=\"left\"))\n",
    "\n",
    "# Variables a descartar (incluye user_id y fecha_segundo_producto_ts)\n",
    "drop_cols = [\n",
    "    \"fecha_segundo_producto_ts\",\n",
    "    \"total_spend\", \"monto_promedio_transaccion\", \"monto_promedio_mensual\",\n",
    "    \"hhi\", \"share_fav\", \"total_transacciones\", \"categoria_favorita\"\n",
    "]\n",
    "df.drop(columns=[c for c in drop_cols if c in df.columns], inplace=True)\n",
    "\n",
    "# Fechas -> timestamp (vectorizado)\n",
    "date_cols = [\"fecha_primer_producto\", \"fecha_segundo_producto\",\n",
    "             \"mes_mas_compras\", \"mes_mayor_monto\"]\n",
    "for c in date_cols:\n",
    "    if c in df.columns:\n",
    "        df[f\"{c}_ts\"] = df[c].astype('int64') // 10**9  # Más eficiente que convertir a int\n",
    "        df.drop(columns=c, inplace=True)\n",
    "\n",
    "# Imputaciones vectorizadas\n",
    "df[\"dias_entre_productos\"] = df[\"dias_entre_productos\"].fillna(0)\n",
    "df[\"variacion_mensual_promedio\"] = df[\"variacion_mensual_promedio\"].fillna(0)\n",
    "df[\"variacion_mensual_promedio_pct\"] = df[\"variacion_mensual_promedio_pct\"].fillna(0)\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "to_scale = [\n",
    "    \"age\", \"dias_entre_productos\", \"antiguedad_cliente\",\n",
    "    \"numero_productos\", \"recencia_transaccion\",\n",
    "    \"variacion_mensual_promedio\", \"variacion_mensual_promedio_pct\"\n",
    "]\n",
    "present = [c for c in to_scale if c in df.columns]\n",
    "# Usar un subset en lugar de crear copias\n",
    "if present:\n",
    "    df[present] = scaler.fit_transform(df[present])\n",
    "\n",
    "# Log1p (vectorizado)\n",
    "if \"total_spend_fav\" in df.columns:\n",
    "    df[\"total_spend_fav\"] = np.log1p(df[\"total_spend_fav\"])\n",
    "\n",
    "# Label encoding (vectorizado) - CON CAMBIO PARA MANEJAR CATEGORICAL\n",
    "cat_vars = [\n",
    "    \"income_range\", \"risk_profile\", \"occupation\", \"age_range_sturges\",\n",
    "    \"primer_producto\", \"segundo_producto\", \"combinacion_productos\",\n",
    "    \"categoria_favorita_monto\"\n",
    "]\n",
    "\n",
    "for c in cat_vars:\n",
    "    if c in df.columns:\n",
    "        # Primero convertir a string para evitar problemas con tipo 'category'\n",
    "        if df[c].dtype.name == 'category':\n",
    "            df[c] = df[c].astype(str)\n",
    "            \n",
    "        # Manejar valores nulos\n",
    "        if df[c].isna().any():\n",
    "            df[c] = df[c].fillna('unknown')\n",
    "            \n",
    "        le = LabelEncoder()\n",
    "        df[c] = le.fit_transform(df[c].astype(str))\n",
    "\n",
    "df.drop(columns=[\"combinacion_productos\"], errors=\"ignore\", inplace=True)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6. Guardar\n",
    "# ------------------------------------------------------------------\n",
    "outfile = DATA_PROD / \"Pipeline_test2.csv\"\n",
    "df.to_csv(outfile, index=False)\n",
    "logging.info(f\"Dataset final guardado: {outfile}  ({df.shape[0]} filas, {df.shape[1]} columnas)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e14581-b703-43ed-a295-0a7e7cb3d8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
