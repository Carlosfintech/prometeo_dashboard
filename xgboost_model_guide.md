# Gu√≠a Completa para Construcci√≥n, Evaluaci√≥n y Ajuste de un Modelo XGBoost

## 1. Resumen del Proceso

Este proyecto cubre de forma integral todas las fases de un pipeline de clasificaci√≥n usando XGBoost para predecir la contrataci√≥n de un seguro. El proceso incluy√≥:

1. **Carga y limpieza de datos.**
2. **Evaluaci√≥n de tres modelos base:** Logistic Regression, Random Forest y XGBoost.
3. **Selecci√≥n del mejor modelo** seg√∫n m√©tricas de validaci√≥n cruzada.
4. **B√∫squeda de hiperpar√°metros √≥ptimos** para XGBoost usando RandomizedSearchCV.
5. **Entrenamiento del modelo final** con esos hiperpar√°metros.
6. **Evaluaci√≥n de la importancia de las caracter√≠sticas.**
7. **Divisi√≥n de los datos** en entrenamiento/test (70/30).
8. **C√°lculo del threshold √≥ptimo por F1 score.**
9. **Evaluaci√≥n en test set** con threshold por defecto (0.5) vs. ajustado.
10. **Validaci√≥n cruzada con y sin threshold ajustado.**
11. **Guardado del modelo final y del threshold.**

---

## 2. Diagrama del Proceso

1. **Evaluaci√≥n de modelos base**
2. **Tuning de hiperpar√°metros para el mejor modelo**
3. **Entrenamiento del modelo final** (X_train)
4. **Evaluaci√≥n de importancia de caracter√≠sticas**
5. **Predicci√≥n de probabilidades sobre X_test**
6. **Curvas ROC y PR**
7. **Selecci√≥n del mejor threshold por F1**
8. **Evaluaci√≥n final en test**
9. **Validaci√≥n cruzada con y sin threshold**
10. **Guardado de modelo y threshold**

---

## 3. Conceptos Clave

### ‚≠ê B√∫squeda de Hiperpar√°metros (RandomizedSearchCV)
Permite probar combinaciones aleatorias de hiperpar√°metros para encontrar las mejores seg√∫n una m√©trica (ej. `roc_auc`). Usa validaci√≥n cruzada interna.

### ‚≠ê Validaci√≥n Cruzada (CV)
Divide los datos en `k` folds. Entrena con `k-1` y valida con el restante. Repite `k` veces y promedia resultados. Asegura que el modelo generaliza bien.

### ‚≠ê Curvas ROC y PR
- **ROC**: mide capacidad de separaci√≥n entre clases.
- **PR**: mejor para clases desbalanceadas. Eval√∫a trade-off entre precisi√≥n y recall.

### ‚≠ê Desbalance de Clases
Cuando una clase ocurre mucho m√°s que otra (ej. 80/20). Impacta m√©tricas como Accuracy. Por eso usamos ROC AUC, F1, Precision y Recall.

### ‚≠ê Threshold (Umbral de Clasificaci√≥n)
Valor de corte para convertir probabilidades en etiquetas 0 o 1. Por defecto es 0.5, pero puede optimizarse por F1 o Recall para mejorar resultados.

### ‚≠ê Importancia de Caracter√≠sticas
Permite interpretar cu√°les variables fueron m√°s relevantes para la predicci√≥n. Puede evaluarse con `feature_importances_`, SHAP o permutaci√≥n.

---

## 4. Fases del Proyecto

### ‚úÖ Fase 1: Evaluaci√≥n de modelos base
```python
evaluate_model(modelo, X, y)
```
Compara Logistic Regression, Random Forest y XGBoost con validaci√≥n cruzada 5-fold. Se escoge el que tenga mejor `roc_auc`.

### ‚úÖ Fase 2: Tuning de hiperpar√°metros (XGBoost)
```python
tune_model(modelo, param_grid_xgb, X, y)
```
RandomizedSearchCV busca combinaciones √≥ptimas de `max_depth`, `n_estimators`, `learning_rate`, etc.

### ‚úÖ Fase 3: Entrenamiento del modelo final
```python
tuned_xgb.fit(X_train, y_train)
```
Modelo entrenado con 70% de los datos (`train_test_split`).

### ‚úÖ Fase 4: Evaluaci√≥n de Importancia de Caracter√≠sticas
```python
importances = tuned_xgb.feature_importances_
```
Visualiza las variables m√°s relevantes con `matplotlib` o SHAP.

### ‚úÖ Fase 5: Evaluaci√≥n sobre Test
```python
y_scores = tuned_xgb.predict_proba(X_test)[:, 1]
```
Se generan probabilidades y se grafican curvas ROC y PR.

### ‚úÖ Fase 6: C√°lculo del Mejor Threshold
```python
best_threshold = thresholds[np.argmax(f1_scores)]
```
Se busca el punto que maximiza el F1 score en `y_test`.

### ‚úÖ Fase 7: Comparaci√≥n Threshold 0.5 vs Ajustado
```python
classification_report(y_test, y_pred_thresh)
```
Eval√∫a el impacto del nuevo umbral sobre la matriz de confusi√≥n y m√©tricas.

### ‚úÖ Fase 8: Validaci√≥n Cruzada con Threshold Ajustado
```python
y_probs_cv = cross_val_predict(..., method='predict_proba')
y_pred_cv_custom = (y_probs_cv >= best_threshold).astype(int)
```
Permite ver el rendimiento general con el nuevo threshold sobre todo el dataset.

---

## 5. Archivos para Producci√≥n

### üìÇ `xgb_model.pkl`
Contiene el modelo entrenado. Usa `.predict_proba()` por defecto.

### üìÇ `xgb_threshold.txt`
Contiene el valor del threshold ajustado (ej. 0.32). Se usa para convertir las probabilidades en 0 o 1.

### üîß C√≥mo usar en producci√≥n
```python
modelo = joblib.load("xgb_model.pkl")
thr = float(open("xgb_threshold.txt").read())
prob = modelo.predict_proba(X_new)[:, 1]
pred = (prob >= thr).astype(int)
```

---

## 6. Recomendaciones y Buenas Pr√°cticas

- ‚úÖ **Separar el modelo y el threshold** para mayor flexibilidad.
- ‚úÖ **Usar ROC AUC** en validaci√≥n cruzada para selecci√≥n de modelo.
- ‚úÖ **Evaluar F1 y Recall** en test, especialmente si las clases est√°n desbalanceadas.
- ‚úÖ **Visualizar curvas ROC y PR**, no confiar solo en accuracy.
- ‚úÖ **Aplicar el threshold ajustado tambi√©n en validaci√≥n cruzada** para entender rendimiento general.
- ‚úÖ **Guardar archivos separados para modelo y umbral**.

---

Esta gu√≠a te permite repetir este proceso paso a paso, evaluando modelos de clasificaci√≥n en contextos reales, mejorando su interpretabilidad, explicabilidad y prepar√°ndolos para su uso en producci√≥n.
