{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "72452906-2c05-4436-b01d-edfb739e9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Fecha de referencia (equivalente a Sys.Date() en el código R)\n",
    "REFERENCE_DATE = pd.Timestamp('2024-01-01')\n",
    "\n",
    "# Cargar los datasets\n",
    "data_path = Path('../data/raw')  # Ajusta esta ruta según tu estructura de directorios\n",
    "transactions = pd.read_csv(data_path / 'transactions.csv')\n",
    "demographics = pd.read_csv(data_path / 'demographics.csv')\n",
    "products = pd.read_csv(data_path / 'products.csv')\n",
    "\n",
    "# Convertir fechas a formato datetime\n",
    "transactions['date'] = pd.to_datetime(transactions['date'])\n",
    "products['contract_date'] = pd.to_datetime(products['contract_date'])\n",
    "\n",
    "# 1. Preparar el dataset de demografía (age_range_sturges)\n",
    "breaks = np.linspace(18, 70, 9)  # 9 puntos de corte para 8 segmentos\n",
    "labels = [\"18–24\", \"25–31\", \"32–38\", \"39–45\", \"46–52\", \"53–59\", \"60–66\", \"67–70\"]\n",
    "demographics['age_range_sturges'] = pd.cut(\n",
    "    demographics['age'], \n",
    "    bins=breaks, \n",
    "    labels=labels, \n",
    "    right=True, \n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# 2. Preparar el dataset de productos\n",
    "products_mod = products.copy()\n",
    "products_mod['product_type'] = products_mod['product_type'].replace('investment_account', 'investment')\n",
    "\n",
    "# Crear variables binarias para cada producto\n",
    "products_wide = pd.pivot_table(\n",
    "    products_mod,\n",
    "    index='user_id',\n",
    "    columns='product_type',\n",
    "    values='contract_date',\n",
    "    aggfunc='count',\n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "# Convertir a indicadores binarios (0/1)\n",
    "product_types = ['checking_account', 'savings_account', 'credit_card', 'insurance', 'investment']\n",
    "for col in product_types:\n",
    "    if col not in products_wide.columns:\n",
    "        products_wide[col] = 0\n",
    "    products_wide[col] = (products_wide[col] > 0).astype(int)\n",
    "\n",
    "# Extraer fechas de primer/segundo producto\n",
    "product_dates = (\n",
    "    products_mod\n",
    "    .sort_values(['user_id', 'contract_date'])\n",
    "    .groupby('user_id')\n",
    "    .apply(lambda x: pd.Series({\n",
    "        'primer_producto': x['product_type'].iloc[0],\n",
    "        'fecha_primer_producto': x['contract_date'].iloc[0],\n",
    "        'segundo_producto': x['product_type'].iloc[1] if len(x) >= 2 else np.nan,\n",
    "        'fecha_segundo_producto': x['contract_date'].iloc[1] if len(x) >= 2 else pd.NaT,\n",
    "    }))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calcular días entre productos y antigüedad del cliente\n",
    "product_dates['dias_entre_productos'] = (\n",
    "    product_dates['fecha_segundo_producto'] - product_dates['fecha_primer_producto']\n",
    ").dt.days\n",
    "\n",
    "product_dates['antiguedad_cliente'] = (\n",
    "    REFERENCE_DATE - product_dates['fecha_primer_producto']\n",
    ").dt.days\n",
    "\n",
    "# Join de products_wide y product_dates\n",
    "products_final = (\n",
    "    product_dates\n",
    "    .merge(products_wide, on='user_id', how='left')\n",
    ")\n",
    "\n",
    "# Calcular número de productos\n",
    "products_final['numero_productos'] = products_final[product_types].sum(axis=1)\n",
    "\n",
    "# Generar combinación de productos\n",
    "def get_product_combination(row):\n",
    "    products = []\n",
    "    for product in product_types:\n",
    "        if row[product] == 1:\n",
    "            products.append(product)\n",
    "    \n",
    "    if not products:\n",
    "        return \"sin_productos\"\n",
    "    \n",
    "    return \" + \".join(products)\n",
    "\n",
    "products_final['combinacion_productos'] = products_final.apply(get_product_combination, axis=1)\n",
    "\n",
    "# Reemplazar con las combinaciones específicas según el patrón del código R\n",
    "combinations_mapping = {\n",
    "    'checking_account': 'checking_account',\n",
    "    'savings_account': 'savings_account',\n",
    "    'savings_account + credit_card': 'credit_card + savings_account',\n",
    "    'savings_account + insurance': 'insurance + savings_account',\n",
    "    'checking_account + insurance': 'checking_account + insurance',\n",
    "    'checking_account + credit_card': 'checking_account + credit_card',\n",
    "    'checking_account + investment': 'checking_account + investment',\n",
    "    'savings_account + investment': 'investment + savings_account'\n",
    "}\n",
    "\n",
    "# Aplicar el mapeo y dejar OTRA_COMBINACION para el resto\n",
    "products_final['combinacion_productos'] = products_final['combinacion_productos'].map(\n",
    "    lambda x: combinations_mapping.get(x, 'OTRA_COMBINACION')\n",
    ")\n",
    "\n",
    "# 3. Preparar el dataset de transacciones\n",
    "# Conteo de transacciones por usuario por categoría\n",
    "category_counts = (\n",
    "    transactions\n",
    "    .groupby('user_id')['merchant_category']\n",
    "    .value_counts()\n",
    "    .unstack(fill_value=0)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Renombrar columnas para seguir el patrón del código R\n",
    "category_counts.columns = [\n",
    "    'user_id' if col == 'user_id' else f'{col}_count' \n",
    "    for col in category_counts.columns\n",
    "]\n",
    "\n",
    "# Calcular estadísticas adicionales por usuario\n",
    "transactions_agg = (\n",
    "    transactions\n",
    "    .groupby('user_id')\n",
    "    .agg(\n",
    "        total_transacciones=('transaction_id', 'count'),\n",
    "        monto_promedio_transaccion=('amount', 'mean')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Unir con los conteos de categorías\n",
    "transactions_agg = transactions_agg.merge(category_counts, on='user_id', how='left')\n",
    "\n",
    "# Determinar la categoría favorita basada en conteos\n",
    "category_cols = [col for col in transactions_agg.columns if col.endswith('_count')]\n",
    "\n",
    "def get_favorite_category(row):\n",
    "    categories = {col.replace('_count', ''): row[col] for col in category_cols}\n",
    "    max_count = max(categories.values())\n",
    "    # En caso de empate, concatenar con \"+\"\n",
    "    fav_categories = [cat for cat, count in categories.items() if count == max_count]\n",
    "    return \" + \".join(fav_categories)\n",
    "\n",
    "transactions_agg['categoria_favorita'] = transactions_agg.apply(get_favorite_category, axis=1)\n",
    "\n",
    "# Análisis temporal (mensual)\n",
    "transactions_monthly = (\n",
    "    transactions\n",
    "    .assign(mes=transactions['date'].dt.to_period('M').dt.to_timestamp())\n",
    "    .groupby(['user_id', 'mes'])\n",
    "    .agg(\n",
    "        monto_mes=('amount', 'sum'),\n",
    "        transacciones_mes=('transaction_id', 'count')\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Identificar mes con más compras y mayor gasto\n",
    "def get_monthly_stats(group):\n",
    "    if group.empty:\n",
    "        return pd.Series({\n",
    "            'mes_mas_compras': pd.NaT,\n",
    "            'mes_mayor_monto': pd.NaT,\n",
    "            'monto_promedio_mensual': np.nan,\n",
    "            'transacciones_promedio_mensual': np.nan\n",
    "        })\n",
    "    \n",
    "    idx_max_tx = group['transacciones_mes'].idxmax()\n",
    "    idx_max_amount = group['monto_mes'].idxmax()\n",
    "    \n",
    "    return pd.Series({\n",
    "        'mes_mas_compras': group.loc[idx_max_tx, 'mes'],\n",
    "        'mes_mayor_monto': group.loc[idx_max_amount, 'mes'],\n",
    "        'monto_promedio_mensual': group['monto_mes'].mean(),\n",
    "        'transacciones_promedio_mensual': group['transacciones_mes'].mean()\n",
    "    })\n",
    "\n",
    "transactions_monthly_agg = (\n",
    "    transactions_monthly\n",
    "    .sort_values(['user_id', 'mes'])\n",
    "    .groupby('user_id')\n",
    "    .apply(get_monthly_stats)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calcular variaciones de un mes al siguiente\n",
    "def calculate_variations(group):\n",
    "    if len(group) <= 1:\n",
    "        return pd.Series({\n",
    "            'variacion_mensual_promedio': np.nan,\n",
    "            'variacion_mensual_promedio_pct': np.nan\n",
    "        })\n",
    "    \n",
    "    diffs = group['monto_mes'].diff().dropna().values\n",
    "    pct_changes = ((group['monto_mes'] / group['monto_mes'].shift(1)) - 1).dropna().values\n",
    "    \n",
    "    return pd.Series({\n",
    "        'variacion_mensual_promedio': np.nanmean(diffs),\n",
    "        'variacion_mensual_promedio_pct': np.nanmean(pct_changes)\n",
    "    })\n",
    "\n",
    "transactions_trend = (\n",
    "    transactions_monthly\n",
    "    .sort_values(['user_id', 'mes'])\n",
    "    .groupby('user_id')\n",
    "    .apply(calculate_variations)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calcular métricas adicionales\n",
    "user_agg = (\n",
    "    transactions\n",
    "    .groupby('user_id')\n",
    "    .agg(\n",
    "        total_spend=('amount', 'sum'),\n",
    "        n_meses_activos=('date', lambda x: x.dt.to_period('M').nunique()),\n",
    "        recencia_transaccion=('date', lambda x: (REFERENCE_DATE - x.max()).days)\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Categoría favorita por monto\n",
    "cat_monto = (\n",
    "    transactions\n",
    "    .groupby(['user_id', 'merchant_category'])\n",
    "    .agg(total_spend_cat=('amount', 'sum'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Encuentrar categoría con mayor monto\n",
    "cat_max = (\n",
    "    cat_monto\n",
    "    .groupby('user_id')\n",
    "    .agg(max_spend_cat=('total_spend_cat', 'max'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Determinar categoría favorita por monto\n",
    "def get_favorite_category_by_amount(group):\n",
    "    categories = group['merchant_category'].tolist()\n",
    "    total_spend_fav = group['total_spend_cat'].sum()\n",
    "    return pd.Series({\n",
    "        'categoria_favorita_monto': ' + '.join(categories),\n",
    "        'total_spend_fav': total_spend_fav\n",
    "    })\n",
    "\n",
    "cat_fav = (\n",
    "    cat_monto\n",
    "    .merge(cat_max, on='user_id')\n",
    "    .query('total_spend_cat == max_spend_cat')\n",
    "    .groupby('user_id')\n",
    "    .apply(get_favorite_category_by_amount)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calcular share de la categoría favorita\n",
    "cat_fav = (\n",
    "    cat_fav\n",
    "    .merge(user_agg[['user_id', 'total_spend']], on='user_id')\n",
    "    .assign(share_fav=lambda x: x['total_spend_fav'] / x['total_spend'])\n",
    ")\n",
    "\n",
    "# Calcular HHI (Herfindahl-Hirschman Index)\n",
    "def calculate_hhi(group):\n",
    "    user_spend = group['total_spend_cat'].sum()\n",
    "    proportions = group['total_spend_cat'] / user_spend\n",
    "    hhi = (proportions ** 2).sum()\n",
    "    return pd.Series({'hhi': hhi})\n",
    "\n",
    "cat_hhi = (\n",
    "    cat_monto\n",
    "    .groupby('user_id')\n",
    "    .apply(calculate_hhi)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Unir todas las agregaciones de transacciones\n",
    "transactions_final = (\n",
    "    transactions_agg\n",
    "    .merge(transactions_monthly_agg, on='user_id', how='left')\n",
    "    .merge(transactions_trend, on='user_id', how='left')\n",
    "    .merge(user_agg, on='user_id', how='left')\n",
    "    .merge(cat_fav[['user_id', 'categoria_favorita_monto', 'total_spend_fav', 'share_fav']], \n",
    "           on='user_id', how='left')\n",
    "    .merge(cat_hhi, on='user_id', how='left')\n",
    ")\n",
    "\n",
    "# 4. Crear el dataset final uniendo todos los datasets\n",
    "df_final = (\n",
    "    demographics\n",
    "    .merge(products_final, on='user_id', how='left')\n",
    "    .merge(transactions_final, on='user_id', how='left')\n",
    ")\n",
    "\n",
    "# 5. Guardar el dataset\n",
    "output_path = data_path.parent / 'processed' / 'data_final_jupyter2.csv'\n",
    "output_path.parent.mkdir(exist_ok=True)\n",
    "df_final.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "31abdbc0-a29b-4937-bb2a-6fd31b39dcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 42 columns):\n",
      " #   Column                          Non-Null Count  Dtype         \n",
      "---  ------                          --------------  -----         \n",
      " 0   user_id                         100 non-null    object        \n",
      " 1   age                             100 non-null    int64         \n",
      " 2   income_range                    100 non-null    object        \n",
      " 3   risk_profile                    100 non-null    object        \n",
      " 4   occupation                      100 non-null    object        \n",
      " 5   age_range_sturges               100 non-null    category      \n",
      " 6   primer_producto                 100 non-null    object        \n",
      " 7   fecha_primer_producto           100 non-null    datetime64[ns]\n",
      " 8   segundo_producto                55 non-null     object        \n",
      " 9   fecha_segundo_producto          55 non-null     datetime64[ns]\n",
      " 10  dias_entre_productos            55 non-null     float64       \n",
      " 11  antiguedad_cliente              100 non-null    int64         \n",
      " 12  checking_account                100 non-null    int64         \n",
      " 13  credit_card                     100 non-null    int64         \n",
      " 14  insurance                       100 non-null    int64         \n",
      " 15  investment                      100 non-null    int64         \n",
      " 16  savings_account                 100 non-null    int64         \n",
      " 17  numero_productos                100 non-null    int64         \n",
      " 18  combinacion_productos           100 non-null    object        \n",
      " 19  total_transacciones             100 non-null    int64         \n",
      " 20  monto_promedio_transaccion      100 non-null    float64       \n",
      " 21  entertainment_count             100 non-null    int64         \n",
      " 22  food_count                      100 non-null    int64         \n",
      " 23  health_count                    100 non-null    int64         \n",
      " 24  shopping_count                  100 non-null    int64         \n",
      " 25  supermarket_count               100 non-null    int64         \n",
      " 26  transport_count                 100 non-null    int64         \n",
      " 27  travel_count                    100 non-null    int64         \n",
      " 28  categoria_favorita              100 non-null    object        \n",
      " 29  mes_mas_compras                 100 non-null    datetime64[ns]\n",
      " 30  mes_mayor_monto                 100 non-null    datetime64[ns]\n",
      " 31  monto_promedio_mensual          100 non-null    float64       \n",
      " 32  transacciones_promedio_mensual  100 non-null    float64       \n",
      " 33  variacion_mensual_promedio      100 non-null    float64       \n",
      " 34  variacion_mensual_promedio_pct  100 non-null    float64       \n",
      " 35  total_spend                     100 non-null    float64       \n",
      " 36  n_meses_activos                 100 non-null    int64         \n",
      " 37  recencia_transaccion            100 non-null    int64         \n",
      " 38  categoria_favorita_monto        100 non-null    object        \n",
      " 39  total_spend_fav                 100 non-null    float64       \n",
      " 40  share_fav                       100 non-null    float64       \n",
      " 41  hhi                             100 non-null    float64       \n",
      "dtypes: category(1), datetime64[ns](4), float64(10), int64(18), object(9)\n",
      "memory usage: 80.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_final.info(memory_usage=\"deep\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f9fc6888-a721-4a19-9d7b-2237be71ca5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id                            0\n",
      "age                                0\n",
      "income_range                       0\n",
      "risk_profile                       0\n",
      "occupation                         0\n",
      "age_range_sturges                  0\n",
      "primer_producto                    0\n",
      "fecha_primer_producto              0\n",
      "segundo_producto                  45\n",
      "fecha_segundo_producto            45\n",
      "dias_entre_productos              45\n",
      "antiguedad_cliente                 0\n",
      "checking_account                   0\n",
      "credit_card                        0\n",
      "insurance                          0\n",
      "investment                         0\n",
      "savings_account                    0\n",
      "numero_productos                   0\n",
      "combinacion_productos              0\n",
      "total_transacciones                0\n",
      "monto_promedio_transaccion         0\n",
      "entertainment_count                0\n",
      "food_count                         0\n",
      "health_count                       0\n",
      "shopping_count                     0\n",
      "supermarket_count                  0\n",
      "transport_count                    0\n",
      "travel_count                       0\n",
      "categoria_favorita                 0\n",
      "mes_mas_compras                    0\n",
      "mes_mayor_monto                    0\n",
      "monto_promedio_mensual             0\n",
      "transacciones_promedio_mensual     0\n",
      "variacion_mensual_promedio         0\n",
      "variacion_mensual_promedio_pct     0\n",
      "total_spend                        0\n",
      "n_meses_activos                    0\n",
      "recencia_transaccion               0\n",
      "categoria_favorita_monto           0\n",
      "total_spend_fav                    0\n",
      "share_fav                          0\n",
      "hhi                                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_final.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "42b9d401-5877-4b8d-8f87-01d83a8bad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputación NA\n",
    "\n",
    "df_final['segundo_producto'] = df_final['segundo_producto'].fillna('none')\n",
    "df_final['fecha_segundo_producto'] = df_final['fecha_segundo_producto'].fillna('1900-01-01')  # Fecha dummy como marcador\n",
    "df_final['dias_entre_productos'] = df_final['dias_entre_productos'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dfd01e16-edce-4a8a-8709-39bc7a1c4568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id                           0\n",
      "age                               0\n",
      "income_range                      0\n",
      "risk_profile                      0\n",
      "occupation                        0\n",
      "age_range_sturges                 0\n",
      "primer_producto                   0\n",
      "fecha_primer_producto             0\n",
      "segundo_producto                  0\n",
      "fecha_segundo_producto            0\n",
      "dias_entre_productos              0\n",
      "antiguedad_cliente                0\n",
      "checking_account                  0\n",
      "credit_card                       0\n",
      "insurance                         0\n",
      "investment                        0\n",
      "savings_account                   0\n",
      "numero_productos                  0\n",
      "combinacion_productos             0\n",
      "total_transacciones               0\n",
      "monto_promedio_transaccion        0\n",
      "entertainment_count               0\n",
      "food_count                        0\n",
      "health_count                      0\n",
      "shopping_count                    0\n",
      "supermarket_count                 0\n",
      "transport_count                   0\n",
      "travel_count                      0\n",
      "categoria_favorita                0\n",
      "mes_mas_compras                   0\n",
      "mes_mayor_monto                   0\n",
      "monto_promedio_mensual            0\n",
      "transacciones_promedio_mensual    0\n",
      "variacion_mensual_promedio        0\n",
      "variacion_mensual_promedio_pct    0\n",
      "total_spend                       0\n",
      "n_meses_activos                   0\n",
      "recencia_transaccion              0\n",
      "categoria_favorita_monto          0\n",
      "total_spend_fav                   0\n",
      "share_fav                         0\n",
      "hhi                               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_final.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3eb5c539-e4b1-44a7-ba55-13cf3b64cd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 42 columns):\n",
      " #   Column                          Non-Null Count  Dtype         \n",
      "---  ------                          --------------  -----         \n",
      " 0   user_id                         100 non-null    object        \n",
      " 1   age                             100 non-null    int64         \n",
      " 2   income_range                    100 non-null    object        \n",
      " 3   risk_profile                    100 non-null    object        \n",
      " 4   occupation                      100 non-null    object        \n",
      " 5   age_range_sturges               100 non-null    category      \n",
      " 6   primer_producto                 100 non-null    object        \n",
      " 7   fecha_primer_producto           100 non-null    datetime64[ns]\n",
      " 8   segundo_producto                100 non-null    object        \n",
      " 9   fecha_segundo_producto          100 non-null    datetime64[ns]\n",
      " 10  dias_entre_productos            100 non-null    float64       \n",
      " 11  antiguedad_cliente              100 non-null    int64         \n",
      " 12  checking_account                100 non-null    int64         \n",
      " 13  credit_card                     100 non-null    int64         \n",
      " 14  insurance                       100 non-null    int64         \n",
      " 15  investment                      100 non-null    int64         \n",
      " 16  savings_account                 100 non-null    int64         \n",
      " 17  numero_productos                100 non-null    int64         \n",
      " 18  combinacion_productos           100 non-null    object        \n",
      " 19  total_transacciones             100 non-null    int64         \n",
      " 20  monto_promedio_transaccion      100 non-null    float64       \n",
      " 21  entertainment_count             100 non-null    int64         \n",
      " 22  food_count                      100 non-null    int64         \n",
      " 23  health_count                    100 non-null    int64         \n",
      " 24  shopping_count                  100 non-null    int64         \n",
      " 25  supermarket_count               100 non-null    int64         \n",
      " 26  transport_count                 100 non-null    int64         \n",
      " 27  travel_count                    100 non-null    int64         \n",
      " 28  categoria_favorita              100 non-null    object        \n",
      " 29  mes_mas_compras                 100 non-null    datetime64[ns]\n",
      " 30  mes_mayor_monto                 100 non-null    datetime64[ns]\n",
      " 31  monto_promedio_mensual          100 non-null    float64       \n",
      " 32  transacciones_promedio_mensual  100 non-null    float64       \n",
      " 33  variacion_mensual_promedio      100 non-null    float64       \n",
      " 34  variacion_mensual_promedio_pct  100 non-null    float64       \n",
      " 35  total_spend                     100 non-null    float64       \n",
      " 36  n_meses_activos                 100 non-null    int64         \n",
      " 37  recencia_transaccion            100 non-null    int64         \n",
      " 38  categoria_favorita_monto        100 non-null    object        \n",
      " 39  total_spend_fav                 100 non-null    float64       \n",
      " 40  share_fav                       100 non-null    float64       \n",
      " 41  hhi                             100 non-null    float64       \n",
      "dtypes: category(1), datetime64[ns](4), float64(10), int64(18), object(9)\n",
      "memory usage: 81.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_final.info(memory_usage=\"deep\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a8577604-853c-4533-a284-e0cf09d63eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas detectadas como fechas:\n",
      "[]\n",
      "Feature Engineering completado. Dataset guardado en: /Users/carloslandaverdealquicirez/Documents/Prometeo_reto/Prometeo_project copy/03.Modelo/data/processed/data_final_fe.csv\n",
      "Dimensiones finales: 100 filas, 37 columnas\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering General - Transformaciones específicas de FE_general.ipynb\n",
    "\n",
    "# 1. Detectar y convertir columnas con fechas\n",
    "posibles_fechas = []\n",
    "\n",
    "for col in df_final.columns:\n",
    "    if df_final[col].dtype == 'object':\n",
    "        try:\n",
    "            pd.to_datetime(df_final[col].dropna().sample(5), errors='raise')\n",
    "            posibles_fechas.append(col)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "print(\"Columnas detectadas como fechas:\")\n",
    "print(posibles_fechas)\n",
    "\n",
    "for col in posibles_fechas:\n",
    "    df_final[col] = pd.to_datetime(df_final[col], errors='coerce')\n",
    "\n",
    "# 2. Convertir explícitamente columnas con 'fecha' en su nombre\n",
    "fecha_cols = [col for col in df_final.columns if \"fecha\" in col.lower()]\n",
    "for col in fecha_cols:\n",
    "    df_final[col] = pd.to_datetime(df_final[col], errors='coerce')\n",
    "\n",
    "# 3. Eliminar variables específicas y categoria_favorita por que no aplica al modelo\n",
    "variables_a_eliminar = [\n",
    "    \"total_spend\",\n",
    "    \"monto_promedio_mensual\",\n",
    "    \"monto_promedio_transaccion\",\n",
    "    \"hhi\",\n",
    "    \"share_fav\",\n",
    "    \"total_transacciones\", \"categoria_favorita\"\n",
    "]\n",
    "\n",
    "df = df_final.drop(columns=variables_a_eliminar, errors=\"ignore\")\n",
    "\n",
    "# Guardar el dataset procesado\n",
    "output_path = Path('/Users/carloslandaverdealquicirez/Documents/Prometeo_reto/Prometeo_project copy/03.Modelo/data/processed/data_final_fe.csv')\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Feature Engineering completado. Dataset guardado en: {output_path}\")\n",
    "print(f\"Dimensiones finales: {df_final_reduced.shape[0]} filas, {df_final_reduced.shape[1]} columnas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f032840d-0a5c-4887-9e22-8650e2640141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 35 columns):\n",
      " #   Column                          Non-Null Count  Dtype         \n",
      "---  ------                          --------------  -----         \n",
      " 0   user_id                         100 non-null    object        \n",
      " 1   age                             100 non-null    int64         \n",
      " 2   income_range                    100 non-null    object        \n",
      " 3   risk_profile                    100 non-null    object        \n",
      " 4   occupation                      100 non-null    object        \n",
      " 5   age_range_sturges               100 non-null    category      \n",
      " 6   primer_producto                 100 non-null    object        \n",
      " 7   fecha_primer_producto           100 non-null    datetime64[ns]\n",
      " 8   segundo_producto                100 non-null    object        \n",
      " 9   fecha_segundo_producto          100 non-null    datetime64[ns]\n",
      " 10  dias_entre_productos            100 non-null    float64       \n",
      " 11  antiguedad_cliente              100 non-null    int64         \n",
      " 12  checking_account                100 non-null    int64         \n",
      " 13  credit_card                     100 non-null    int64         \n",
      " 14  insurance                       100 non-null    int64         \n",
      " 15  investment                      100 non-null    int64         \n",
      " 16  savings_account                 100 non-null    int64         \n",
      " 17  numero_productos                100 non-null    int64         \n",
      " 18  combinacion_productos           100 non-null    object        \n",
      " 19  entertainment_count             100 non-null    int64         \n",
      " 20  food_count                      100 non-null    int64         \n",
      " 21  health_count                    100 non-null    int64         \n",
      " 22  shopping_count                  100 non-null    int64         \n",
      " 23  supermarket_count               100 non-null    int64         \n",
      " 24  transport_count                 100 non-null    int64         \n",
      " 25  travel_count                    100 non-null    int64         \n",
      " 26  mes_mas_compras                 100 non-null    datetime64[ns]\n",
      " 27  mes_mayor_monto                 100 non-null    datetime64[ns]\n",
      " 28  transacciones_promedio_mensual  100 non-null    float64       \n",
      " 29  variacion_mensual_promedio      100 non-null    float64       \n",
      " 30  variacion_mensual_promedio_pct  100 non-null    float64       \n",
      " 31  n_meses_activos                 100 non-null    int64         \n",
      " 32  recencia_transaccion            100 non-null    int64         \n",
      " 33  categoria_favorita_monto        100 non-null    object        \n",
      " 34  total_spend_fav                 100 non-null    float64       \n",
      "dtypes: category(1), datetime64[ns](4), float64(5), int64(17), object(8)\n",
      "memory usage: 70.9 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df1.info(memory_usage=\"deep\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2960c53e-dff0-422f-9005-4e49c866330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_a_eliminar = [\n",
    "    \"Unnamed: 0\", \"user_id\",\n",
    "]\n",
    "\n",
    "fechas = [\n",
    "    \"fecha_primer_producto\", \"fecha_segundo_producto\",\n",
    "    \"mes_mas_compras\", \"mes_mayor_monto\"\n",
    "]\n",
    "\n",
    "binarias_explicit = ['checking_account', 'savings_account', 'credit_card', 'investment']\n",
    "\n",
    "\n",
    "df.drop(columns=[col for col in cols_a_eliminar if col in df.columns], inplace=True)\n",
    "\n",
    "# Convertir fechas\n",
    "for col in fechas:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "# Convertir fechas y extraer timestamp  por requerimiento de sklearn\n",
    "for col in fechas:\n",
    "    if col in df.columns:\n",
    "        # Convertir la columna a datetime\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "        # >>> MODIFICACIÓN: Convertir fecha a formato numérico (timestamp en nanosegundos) usando astype\n",
    "        df[col + \"_ts\"] = df[col].astype('int64')\n",
    "        # Eliminar la columna original si no es necesaria\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# Aplicar log1p para reducir asimetría de valores altos\n",
    "if 'total_spend_fav' in df.columns:\n",
    "    df['total_spend_fav'] = np.log1p(df['total_spend_fav'])\n",
    "\n",
    "# Aplicar log1p para valores extremos en proporciones\n",
    "if 'variacion_mensual_promedio_pct' in df.columns:\n",
    "    df['variacion_mensual_promedio_pct'] = np.log1p(df['variacion_mensual_promedio_pct'])\n",
    "\n",
    "# Winsorización de variable con outliers importantes\n",
    "if 'variacion_mensual_promedio' in df.columns:\n",
    "    p01 = df['variacion_mensual_promedio'].quantile(0.01)\n",
    "    p99 = df['variacion_mensual_promedio'].quantile(0.99)\n",
    "    df['variacion_mensual_promedio'] = df['variacion_mensual_promedio'].clip(p01, p99)\n",
    "\n",
    "# Escalar recencia para estabilidad del gradiente\n",
    "if 'recencia_transaccion' in df.columns:\n",
    "    df['recencia_transaccion'] = StandardScaler().fit_transform(df[['recencia_transaccion']])\n",
    "\n",
    "# Escalar otras variables numéricas continuas\n",
    "escalar_xgb = [\n",
    "    'age', 'dias_entre_productos', 'antiguedad_cliente', 'numero_productos',\n",
    "    'entertainment_count', 'food_count', 'health_count', 'shopping_count',\n",
    "    'supermarket_count', 'transport_count', 'travel_count'\n",
    "]\n",
    "escalar_xgb = [col for col in escalar_xgb if col in df.columns]\n",
    "df[escalar_xgb] = StandardScaler().fit_transform(df[escalar_xgb])\n",
    "\n",
    "# Convertir variables binarias explícitas a tipo booleano\n",
    "for col in binarias_explicit:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].map({1: True, 0: False}).astype(bool)\n",
    "\n",
    "# Codificación con LabelEncoder para categóricas (no binarias)\n",
    "categoricas = [\n",
    "    'income_range', 'risk_profile', 'occupation', 'age_range_sturges',\n",
    "    'primer_producto', 'segundo_producto', 'combinacion_productos',\n",
    "    'categoria_favorita_monto'\n",
    "]\n",
    "for col in categoricas:\n",
    "    if col in df.columns:\n",
    "        df[col] = LabelEncoder().fit_transform(df[col].astype(str))\n",
    "\n",
    "\n",
    "columnas_a_quitar = ['fecha_segundo_producto_ts', 'combinacion_productos', 'segundo_producto']\n",
    "\n",
    "df = df.drop(columns=columnas_a_quitar, errors=\"ignore\")\n",
    "\n",
    "\n",
    "y = df['insurance']\n",
    "X = df.drop(columns=['insurance'])\n",
    "\n",
    "# Guardar datasets preparados para modelado\n",
    "X.to_csv(\"../data/processed/X_xgb_reduced_TEST.csv\", index=False)\n",
    "y.to_csv(\"../data/processed/y_xgb_reduced_TEST.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9b20914d-0f4c-4da9-bab7-1e2199ffbe22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 31 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   age                             100 non-null    float64\n",
      " 1   income_range                    100 non-null    int64  \n",
      " 2   risk_profile                    100 non-null    int64  \n",
      " 3   occupation                      100 non-null    int64  \n",
      " 4   age_range_sturges               100 non-null    int64  \n",
      " 5   primer_producto                 100 non-null    int64  \n",
      " 6   dias_entre_productos            100 non-null    float64\n",
      " 7   antiguedad_cliente              100 non-null    float64\n",
      " 8   checking_account                100 non-null    bool   \n",
      " 9   credit_card                     100 non-null    bool   \n",
      " 10  insurance                       100 non-null    int64  \n",
      " 11  investment                      100 non-null    bool   \n",
      " 12  savings_account                 100 non-null    bool   \n",
      " 13  numero_productos                100 non-null    float64\n",
      " 14  entertainment_count             100 non-null    float64\n",
      " 15  food_count                      100 non-null    float64\n",
      " 16  health_count                    100 non-null    float64\n",
      " 17  shopping_count                  100 non-null    float64\n",
      " 18  supermarket_count               100 non-null    float64\n",
      " 19  transport_count                 100 non-null    float64\n",
      " 20  travel_count                    100 non-null    float64\n",
      " 21  transacciones_promedio_mensual  100 non-null    float64\n",
      " 22  variacion_mensual_promedio      100 non-null    float64\n",
      " 23  variacion_mensual_promedio_pct  100 non-null    float64\n",
      " 24  n_meses_activos                 100 non-null    int64  \n",
      " 25  recencia_transaccion            100 non-null    float64\n",
      " 26  categoria_favorita_monto        100 non-null    int64  \n",
      " 27  total_spend_fav                 100 non-null    float64\n",
      " 28  fecha_primer_producto_ts        100 non-null    int64  \n",
      " 29  mes_mas_compras_ts              100 non-null    int64  \n",
      " 30  mes_mayor_monto_ts              100 non-null    int64  \n",
      "dtypes: bool(4), float64(16), int64(11)\n",
      "memory usage: 21.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info(memory_usage=\"deep\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ccf9ca-33fe-482e-8571-5fe45ce32759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed58daa-0f98-4294-bab2-da6f146c9893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
